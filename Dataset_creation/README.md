# STT Dataset Generator

Una herramienta para generar datasets de evaluaci√≥n de sistemas de reconocimiento de voz (STT) usando OpenAI para generar transcripciones estructuradas y m√∫ltiples proveedores TTS (ElevenLabs y Google Gemini) para crear conversaciones de audio.

## Caracter√≠sticas

- ü§ñ **Generaci√≥n autom√°tica de conversaciones** usando OpenAI 
- üéôÔ∏è **S√≠ntesis de voz realista** usando ElevenLabs TTS o Google Gemini TTS
- üìä **Salida estructurada** con modelos Pydantic
- ‚ö° **Procesamiento as√≠ncrono** para generaci√≥n eficiente en lotes
- üéõÔ∏è **Interfaz de l√≠nea de comandos** f√°cil de usar
- üìÅ **Organizaci√≥n autom√°tica** de archivos de dataset
- üîÑ **M√∫ltiples proveedores TTS** - ElevenLabs (premium) y Gemini (gratuito)

## Instalaci√≥n

1. Clona el repositorio y navega al directorio:
```bash
cd Dataset_creation
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

2.b Requisito del sistema: FFmpeg (obligatorio)

FFmpeg es necesario para la manipulaci√≥n/convertido de audio (usado por pydub y para convertir WAV‚ÜîMP3).

- macOS (Homebrew):
```bash
brew install ffmpeg
```

- Linux (Debian/Ubuntu):
```bash
sudo apt update && sudo apt install -y ffmpeg
```

- Linux (Fedora/RHEL):
```bash
sudo dnf install -y ffmpeg
```

- Windows (winget o Chocolatey):
```powershell
# Con Chocolatey
choco install ffmpeg
```

Verificaci√≥n r√°pida:
```bash
ffmpeg -version
```

Recuerda refrescar tu app o terminal si ffmpeg -version is not found before running the commands

3. Configura las claves API:
```bash
# Crea un archivo .env con tus claves API
echo "OPENAI_API_KEY=tu_clave_openai_aqu√≠" > .env

# Para ElevenLabs (opcional - premium)
echo "ELEVEN_API_KEY=tu_clave_elevenlabs_aqu√≠" >> .env

# Para Google Gemini TTS (opcional - gratuito)
echo "GOOGLE_API_KEY=tu_clave_google_aqu√≠" >> .env
```

## Uso R√°pido

### 1. Generar una conversaci√≥n r√°pida

#### Con ElevenLabs (premium)
```bash
python cli.py quick-generate \
  --title "Consulta M√©dica" \
  --description "Un doctor consulta con un paciente sobre s√≠ntomas" \
  --context "Consultorio m√©dico" \
  --participants "Doctor,Paciente" \
  --duration 90 \
  --difficulty medium \
  --domain medical \
  --language es \
  --tts-provider elevenlabs
```

#### Con Google Gemini TTS (gratuito)
```bash
python cli.py quick-generate \
  --title "Consulta M√©dica" \
  --description "Un doctor consulta con un paciente sobre s√≠ntomas" \
  --context "Consultorio m√©dico" \
  --participants "Doctor,Paciente" \
  --duration 90 \
  --difficulty medium \
  --domain medical \
  --language es \
  --tts-provider gemini
```

### 2. Crear configuraci√≥n de muestra
```bash
python cli.py create-sample-config --output scenarios.json
```

### 3. Generar dataset desde configuraci√≥n

#### Con ElevenLabs
```bash
# Para un √∫nico escenario (prueba)
python cli.py generate --scenarios scenarios.json --single --tts-provider elevenlabs

# Para todo el lote
python cli.py generate --scenarios scenarios.json --max-concurrent 3 --tts-provider elevenlabs
```

#### Con Google Gemini TTS
```bash
# Para un √∫nico escenario (prueba)
python cli.py generate --scenarios scenarios.json --single --tts-provider gemini

# Para todo el lote
python cli.py generate --scenarios scenarios.json --max-concurrent 3 --tts-provider gemini
```

### 4. Generar audio desde un transcript existente

Cuando ya tienes un archivo JSON de transcripci√≥n (estructura `GeneratedConversation`) y solo quieres sintetizar el audio:

#### ElevenLabs (premium)
```bash
python cli.py synthesize-from-transcript \
  --transcript generated_datasets/gemini_test_medication/cardiology_consultation_01_b6e406b1_transcript.json \
  --language es \
  --tts-provider elevenlabs
```

#### Google Gemini TTS (gratuito)
```bash
python cli.py synthesize-from-transcript \
  --transcript generated_datasets/gemini_test_medication/cardiology_consultation_01_b6e406b1_transcript.json \
  --language es \
  --tts-provider gemini
```

Opcional: usar tus propios mapeos de voces
```bash
python cli.py synthesize-from-transcript \
  -t path/to/transcript.json \
  -l en \
  --tts-provider gemini \
  --voice-mappings voice_mappings_gemini_en.json
```

Notas:
- Si no pasas `--output`, el archivo se crear√° junto al transcript como `<base>_conversation.mp3` (ElevenLabs) o `<base>_conversation.wav` (Gemini).
- Si no pasas `--voice-mappings`, se cargar√°n autom√°ticamente los mapeos por idioma y proveedor.

## Gu√≠a Paso a Paso Completa

Esta gu√≠a te lleva desde la configuraci√≥n inicial hasta la generaci√≥n de datasets listos para evaluaci√≥n STT.

### Paso 1: Configuraci√≥n Inicial

#### 1.1 Instalar Dependencias
```bash
# Instalar todas las dependencias requeridas
pip install -r requirements.txt
```

#### 1.2 Configurar Variables de Entorno
Crea un archivo `.env` en el directorio ra√≠z:
```bash
# API Keys requeridas
OPENAI_API_KEY=your_openai_api_key_here

# TTS Provider Keys (al menos una requerida)
ELEVEN_API_KEY=your_elevenlabs_api_key_here      # Para ElevenLabs (premium)
GOOGLE_API_KEY=your_google_api_key_here          # Para Google Gemini TTS (gratuito)
```

**Nota**: Aseg√∫rate de que las claves API tengan permisos adecuados:
- **OpenAI**: Para usar GPT-4 en generaci√≥n de conversaciones
- **ElevenLabs**: Para s√≠ntesis de voz premium (requiere suscripci√≥n)
- **Google**: Para Gemini TTS (gratuito con cuotas)

### Paso 2: Preparar Archivos de Configuraci√≥n

#### 2.1 Crear Archivo de Escenarios
Los escenarios definen las conversaciones que se generar√°n:

```bash
# Crear archivo de escenarios b√°sico con ejemplos m√©dicos
python cli.py create-sample-config
```

Esto crea `scenarios.json` con ejemplos de conversaciones m√©dicas especializadas.

#### 2.2 Editar Escenarios Personalizados
Edita `scenarios.json` para definir tus propios escenarios:

```json
{
  "scenario_id": "consulta_cardiologia_01",
  "title": "Consulta Cardiolog√≠a - Arritmias",
  "description": "Cardi√≥logo explica arritmias complejas al paciente",
  "context": "Consulta especializada donde el cardi√≥logo explica arritmias ventriculares y discute anticoagulantes",
  "participants": ["Cardi√≥logo", "Paciente"],
  "target_duration": 180,
  "difficulty_level": "hard",
  "language": "es",
  "domain": "cardiology"
}
```

**Consejos para editar escenarios:**
- **scenario_id**: Identificador √∫nico, usa formato `tipo_numero`
- **participants**: Roles que participar√°n (deben existir en `voice_mappings_*.json`)
- **difficulty_level**: "easy", "medium", "hard" (afecta complejidad t√©cnica)
- **language**: "es" para espa√±ol, "en" para ingl√©s
- **target_duration**: Duraci√≥n objetivo en segundos (180-300 recomendado)

#### 2.3 Configurar Mapeos de Voces
Los archivos `voice_mappings_es.json` y `voice_mappings_en.json` mapean roles a voces de ElevenLabs:

```json
{
  "speaker_name": "Cardi√≥logo",
  "voice_id": "ID_DE_VOICE_ELEVENLABS",
  "voice_name": "Nombre de la Voz",
  "voice_description": "Voz masculina profesional para cardi√≥logos"
}
```

**Para obtener voice_id de ElevenLabs:**
Visitar
https://elevenlabs.io/app/voice-library
Hacer click en los 3 puntos de la derecha de la voz deseada
Click en "Copy Voice ID"

O desde la terminal:
```bash
# Listar voces disponibles (requiere API key configurada)
curl -X GET "https://api.elevenlabs.io/v1/voices" \
  -H "xi-api-key: $ELEVEN_API_KEY"
```

### Paso 3: Generar Dataset B√°sico

#### 3.1 Generaci√≥n R√°pida (Prueba)
```bash
# Generar una conversaci√≥n simple para probar el sistema
python cli.py quick-generate \
  --context "Consulta m√©dica b√°sica sobre s√≠ntomas de gripe" \
  --participants "Doctor,Paciente" \
  --language es
```

**Resultado:** Un archivo MP3 y JSON en `generated_datasets/quick_*`
- `conversation.mp3`: Audio de la conversaci√≥n generada
- `conversation.json`: Transcripci√≥n estructurada con metadatos

#### 3.2 Generaci√≥n por Lotes
```bash
# Generar m√∫ltiples conversaciones desde archivo de escenarios
python cli.py generate \
  --scenarios scenarios.json \
  --max-concurrent 2
```

**Opciones importantes:**
- `--max-concurrent`: N√∫mero de conversaciones a generar en paralelo (2-5 recomendado)
- `--output-dir`: Directorio personalizado para salida
- `--language`: Idioma espec√≠fico ("es", "en", "auto")

**Resultado esperado:**
```
generated_datasets/
‚îî‚îÄ‚îÄ batch_20240101_120000/
    ‚îú‚îÄ‚îÄ conversation_01.json          # Transcripci√≥n estructurada
    ‚îú‚îÄ‚îÄ conversation_01.mp3           # Audio generado
    ‚îú‚îÄ‚îÄ conversation_02.json
    ‚îú‚îÄ‚îÄ conversation_02.mp3
    ‚îî‚îÄ‚îÄ metadata.json                 # Informaci√≥n del lote
```

### Paso 4: Post-Procesamiento de Audio (Opcional pero Recomendado)

#### 4.1 A√±adir Variabilidad Realista
```bash
# Procesar un archivo individual con efectos aleatorios
python cli.py process-audio \
  -i generated_datasets/batch_xxx/conversation_01.mp3 \
  --noise-level 0.05 \
  --speed-variation 0.1 \
  --volume-variation 0.2 \
  --seed 42
```

#### 4.2 Procesar Directorio Completo
```bash
# Procesar todo un lote con efectos aleatorios
python cli.py process-audio \
  -i generated_datasets/batch_xxx \
  --noise-level 0.03 \
  --speed-variation 0.15 \
  --volume-variation 0.3
```

**Efectos aplicados aleatoriamente:**
- **Ruido de fondo**: Simula ambientes ruidosos (oficinas, hospitales)
- **Variaci√≥n de velocidad**: Diferentes ritmos de habla (¬±10-15%) (WIP)
- **Variaci√≥n de volumen**: Diferentes distancias de grabaci√≥n (¬±0.2-0.3dB) (WIP)

**Resultado:**
```
conversation_01.mp3
‚îú‚îÄ‚îÄ conversation_01_processed_a1b2c3.mp3    # Con ruido de fondo
‚îú‚îÄ‚îÄ conversation_01_processed_d4e5f6.mp3    # Velocidad modificada
‚îî‚îÄ‚îÄ conversation_01_processed_g7h8i9.mp3    # Volumen ajustado
```

### Paso 5: Validaci√≥n y Verificaci√≥n

#### 5.1 Validar Dataset
```bash
# Verificar integridad del dataset generado
python cli.py validate \
  --directory generated_datasets/batch_xxx
```

**Verificaciones realizadas:**
- ‚úÖ Archivos de audio existen y son v√°lidos
- ‚úÖ Transcripciones JSON tienen estructura correcta
- ‚úÖ Metadatos incluyen informaci√≥n requerida
- ‚úÖ Duraciones de audio coinciden con expectativas

#### 5.2 Obtener Informaci√≥n del Dataset
```bash
# Mostrar estad√≠sticas del lote generado
python cli.py info \
  --directory generated_datasets/batch_xxx
```

### Paso 6: Flujo de Trabajo Completo

#### Ejemplo: Dataset M√©dico en Espa√±ol Completo
```bash
# 1. Configurar API keys
echo "OPENAI_API_KEY=sk-..." > .env
echo "ELEVEN_API_KEY=..." >> .env
echo "GOOGLE_API_KEY=..." >> .env

# 2. Crear escenarios m√©dicos de ejemplo
python cli.py create-sample-config

# 3. Editar escenarios para especialidades espec√≠ficas
# (editar scenarios.json manualmente)

# 4. Generar dataset b√°sico con ElevenLabs (premium)
python cli.py generate \
  --scenarios scenarios.json \
  --max-concurrent 3 \
  --language es \
  --tts-provider elevenlabs

# O con Google Gemini TTS (gratuito)
python cli.py generate \
  --scenarios scenarios.json \
  --max-concurrent 3 \
  --language es \
  --tts-provider gemini

# 5. A√±adir variabilidad para evaluaci√≥n robusta
python cli.py process-audio \
  -i generated_datasets/batch_latest \
  --noise-level 0.05 \
  --speed-variation 0.1

# 6. Validar resultado final
python cli.py validate \
  --directory generated_datasets/batch_latest
```

### Paso 7: Estructura Final del Dataset

Despu√©s de completar todos los pasos, tendr√°s:

```
generated_datasets/
‚îî‚îÄ‚îÄ batch_20240101_120000/
    ‚îú‚îÄ‚îÄ metadata.json                    # Informaci√≥n del lote
    ‚îú‚îÄ‚îÄ conversation_01.json            # Transcripci√≥n original
    ‚îú‚îÄ‚îÄ conversation_01.mp3             # Audio original
    ‚îú‚îÄ‚îÄ conversation_01_processed_abc123.mp3  # Audio procesado 1
    ‚îú‚îÄ‚îÄ conversation_01_processed_def456.mp3  # Audio procesado 2
    ‚îú‚îÄ‚îÄ conversation_02.json
    ‚îú‚îÄ‚îÄ conversation_02.mp3
    ‚îî‚îÄ‚îÄ batch_cardiology_consultation_01_processed/
        ‚îî‚îÄ‚îÄ [archivos procesados adicionales]
```

### Consejos y Mejores Pr√°cticas

#### Configuraci√≥n de Escenarios
- **Dif√≠cil**: Incluye terminolog√≠a m√©dica espec√≠fica, nombres de drogas, s√≠ntomas complejos
- **Participantes**: Usa roles espec√≠ficos (Cardi√≥logo, Enfermera, Familiar del Paciente)
- **Duraci√≥n**: 180-300 segundos para conversaciones realistas
- **Dominio**: Especifica el campo m√©dico para terminolog√≠a apropiada

#### Optimizaci√≥n de Audio
- **Post-procesamiento**: Mejora dr√°sticamente la evaluaci√≥n STT en condiciones reales
- **Seeds**: Usa `--seed` para resultados reproducibles en tests
- **Variabilidad**: Combina diferentes niveles de ruido y velocidad

#### Gesti√≥n de Recursos
- **Concurrente**: Ajusta `--max-concurrent` seg√∫n l√≠mites de tu plan de API
- **Lotes**: Divide escenarios grandes en archivos separados
- **Monitoreo**: Revisa logs para identificar problemas de API temprano

### 4. Procesar audio (opcional)
```bash
# Procesar archivo individual con efectos aleatorios
python cli.py process-audio -i archivo.mp3 --seed 42

# Procesar directorio completo
python cli.py process-audio -i ./generated_datasets/batch_xxx

# Procesar con par√°metros personalizados
python cli.py process-audio \
  -i ./generated_datasets/batch_xxx \
  --noise-level 0.08 \
  --speed-variation 0.15 \
  --volume-variation 0.3 \
  --noise-types "white" \
  --seed 123
```

### 5. Validar dataset generado
```bash
python cli.py validate --directory ./generated_datasets/batch_20231201_143022
```

## Estructura de Archivos de Salida

```
generated_datasets/
‚îî‚îÄ‚îÄ batch_20231201_143022/
    ‚îú‚îÄ‚îÄ batch_20231201_143022_metadata.json    # Metadatos del lote
    ‚îú‚îÄ‚îÄ medical_consultation_01_a1b2c3d4_conversation.mp3      # Audio
    ‚îú‚îÄ‚îÄ medical_consultation_01_a1b2c3d4_transcript.json       # Transcripci√≥n
    ‚îú‚îÄ‚îÄ medical_consultation_01_a1b2c3d4_metadata.json         # Metadatos entrada
    ‚îî‚îÄ‚îÄ ... (m√°s entradas)
```

## Configuraci√≥n de Escenarios

Los escenarios se definen en formato JSON. Ejemplo:

```json
[
  {
    "scenario_id": "medical_consultation_01",
    "title": "Consulta M√©dica",
    "description": "Un doctor consulta con un paciente sobre s√≠ntomas",
    "context": "Consultorio m√©dico donde un doctor examina a un paciente con s√≠ntomas de gripe",
    "participants": ["Doctor", "Paciente"],
    "target_duration": 90,
    "difficulty_level": "medium",
    "language": "en",
    "domain": "medical"
  }
]
```

### Campos de Escenario

- **scenario_id**: Identificador √∫nico
- **title**: T√≠tulo de la conversaci√≥n
- **description**: Descripci√≥n breve
- **context**: Contexto o setting para la conversaci√≥n
- **participants**: Lista de nombres/roles de participantes
- **target_duration**: Duraci√≥n objetivo en segundos
- **difficulty_level**: "easy", "medium", "hard"
- **language**: C√≥digo de idioma (ej: "en", "es")
- **domain**: Dominio espec√≠fico (medical, business, casual, etc.)

### Niveles de Dificultad

- **Easy**: Frases claras y simples, superposiciones m√≠nimas, habla formal
- **Medium**: Habla natural con algunos elementos informales, superposiciones ocasionales  
- **Hard**: Frases complejas, habla informal, interrupciones, referencias a ruido de fondo

## Configuraci√≥n de Voces

El sistema carga autom√°ticamente los mapeos de voz desde archivos JSON seg√∫n el idioma especificado. Puedes personalizar las voces editando los archivos `voice_mappings_en.json` (ingl√©s) y `voice_mappings_es.json` (espa√±ol)

### Mapeos por Idioma
- **Espa√±ol**: `voice_mappings_es.json` (25 voces optimizadas para espa√±ol)
- **Ingl√©s**: `voice_mappings_en.json` (25 voces optimizadas para ingl√©s)
- **Selecci√≥n autom√°tica**: Basada en el campo `language` del escenario

### Voces Recomendadas por Especialidad M√©dica
**Profesionales M√©dicos:**
- **Cardi√≥logo**: Rachel (voz profesional y precisa)
- **Onc√≥logo/Radio-onc√≥logo**: Sarah (voz autoritaria y emp√°tica)
- **Neurocirujano/Neur√≥logo**: Adam (voz calmada y t√©cnica)
- **Psiquiatra**: Sarah (voz emp√°tica y profesional)
- **Cirujano/Anestesi√≥logo**: Rachel (voz autoritaria y calmada)

**Pacientes y Familiares:**
- **Paciente**: Domi (voz conversacional y natural)
- **Padre**: Domi (voz preocupada masculina)
- **Madre**: Rachel (voz angustiada femenina)
- **Familiar**: Domi (voz familiar preocupada)

**Personal M√©dico Auxiliar:**
- **Enfermera**: Sarah (voz clara y profesional)
- **Residente**: Josh (voz joven y t√©cnica)
- **Perfusionista**: Josh (voz t√©cnica especializada)
- **Endoscopista**: Adam (voz t√©cnica especializada)

## Configuraci√≥n de Audio

La herramienta utiliza **ElevenLabs v3** con configuraci√≥n optimizada para STT:

### Configuraci√≥n Predeterminada
- **Modelo**: `eleven_v3` (modelo m√°s avanzado con audio tags)
- **Formato**: `mp3_44100_128` (alta calidad, tama√±o optimizado)
- **Estabilidad**: `0.5` (equilibrio entre expresividad y consistencia)
  - `0.3`: Creativa (m√°s emocional, mejor para tags)
  - `0.5`: Natural (equilibrio recomendado)
  - `0.8`: Robusta (muy estable, menos expresiva)
- **Speaker Boost**: `True` (mejora similitud con voz original)
- **Text Normalization**: `auto` (manejo autom√°tico de n√∫meros y s√≠mbolos)
- **Audio Tags**: `True` (habilitado para expresividad emocional)

### Audio Tags Autom√°ticos (v3)
La herramienta aplica autom√°ticamente audio tags basados en caracter√≠sticas de voz generadas por OpenAI:

**Mapeo Autom√°tico de Caracter√≠sticas a Tags:**
- `"anxious"` ‚Üí `[nervous]`
- `"whispering"` ‚Üí `[whispers]`
- `"excited"` ‚Üí `[excited]`
- `"questioning"` ‚Üí `[questioning]`
- `"professional"` ‚Üí `[professional]`
- `"warm"` ‚Üí `[warm]`
- `"curious"` ‚Üí `[curious]`
- `"frustrated"` ‚Üí `[frustrated]`
- `"reassuring"` ‚Üí `[reassuring]`

**Tags Contextuales Adicionales:**
- `[pause]` - Pausas naturales entre turnos
- `[emphasis]` - √ânfasis en t√©rminos t√©cnicos, nombres de medicamentos, siglas m√©dicas
- `[sighs]` - Suspiros para marcadores de duda ("um", "well", "uh")

### Configuraci√≥n por Idioma
- **Espa√±ol (`--language es`)**: Usa mapeos optimizados para espa√±ol
- **Ingl√©s (`--language en`)**: Usa mapeos optimizados para ingl√©s
- **Otros idiomas**: Compatibilidad autom√°tica con voces multiling√ºes

### Calidad de Audio
- **Archivo de salida**: MP3 de alta calidad (~1.2-1.5MB por conversaci√≥n)
- **Tasa de muestreo**: 44.1kHz (calidad CD)
- **Bitrate**: 128kbps (equilibrio calidad/tama√±o)
- **Conversi√≥n**: Una sola llamada API usando Text to Dialogue

## Procesamiento de Audio Post-Generaci√≥n

El sistema incluye herramientas avanzadas para **post-procesamiento de audio** que a√±aden variabilidad realista a los datasets, mejorando la evaluaci√≥n de sistemas STT en condiciones del mundo real.

### Efectos Disponibles

#### **Ruido de Fondo**
- **Tipos**: Blanco, rosa, marr√≥n (dependiendo de la versi√≥n de pydub)
- **Nivel**: Configurable de 0.0 a 0.2
- **Prop√≥sito**: Simular ambientes ruidosos (oficinas, hospitales, transporte)

#### **Variaci√≥n de Velocidad**
- **Rango**: ¬± porcentaje configurable (default: ¬±10%)
- **Aplicaci√≥n**: 70% de probabilidad de modificaci√≥n
- **Prop√≥sito**: Simular diferentes ritmos de habla

#### **Variaci√≥n de Volumen**
- **Rango**: ¬±dB configurable (default: ¬±0.2dB)
- **Aplicaci√≥n**: 80% de probabilidad de modificaci√≥n
- **Prop√≥sito**: Simular diferentes distancias y condiciones de grabaci√≥n

### Beneficios para Evaluaci√≥n STT

‚úÖ **Mayor Robustez**: Entrenar modelos con audio variable
‚úÖ **Realismo**: Simular condiciones del mundo real
‚úÖ **Diversidad**: Crear m√∫ltiples variantes del mismo contenido
‚úÖ **Evaluaci√≥n**: Medir rendimiento en condiciones adversas
‚úÖ **Reproducibilidad**: Usar `--seed` para resultados consistentes

### Archivos Generados

```
original_audio.mp3
‚îú‚îÄ‚îÄ original_audio_processed_a1b2c3.mp3  # Con ruido + velocidad
‚îú‚îÄ‚îÄ original_audio_processed_d4e5f6.mp3  # Solo volumen modificado
‚îî‚îÄ‚îÄ original_audio_processed_g7h8i9.mp3  # Sin modificaciones
```

### Ejemplos de Uso

```bash
# Dataset b√°sico para evaluaci√≥n est√°ndar
python cli.py generate --scenarios scenarios.json

# Dataset con variabilidad para evaluaci√≥n robusta
python cli.py generate --scenarios scenarios.json
python cli.py process-audio -i ./generated_datasets/batch_xxx \
  --noise-level 0.05 --speed-variation 0.1 --volume-variation 0.2

# Crear m√∫ltiples variantes de un archivo espec√≠fico
python cli.py process-audio -i archivo.mp3 --seed 42
python cli.py process-audio -i archivo.mp3 --seed 43
python cli.py process-audio -i archivo.mp3 --seed 44
```

## API Program√°tica

Tambi√©n puedes usar la herramienta program√°ticamente:

```python
from dotenv import load_dotenv
from dataset_generator import STTDatasetGenerator
from models import ConversationScenario

load_dotenv()

# Inicializar generador
generator = STTDatasetGenerator()

# Crear escenario
scenario = ConversationScenario(
    scenario_id="test_01",
    title="Conversaci√≥n de Prueba",
    description="Una conversaci√≥n simple para probar",
    context="Llamada telef√≥nica casual",
    participants=["Alice", "Bob"],
    target_duration=60,
    difficulty_level="easy"
)

# Generar entrada de dataset
entry = generator.generate_single_dataset_entry(scenario)
print(f"Generado: {entry.entry_id}")
```

## Uso para Evaluaci√≥n STT

Los datasets generados est√°n listos para evaluaci√≥n STT:

1. **Archivo de Audio**: Conversaci√≥n multiparlante en MP3
2. **Transcripci√≥n**: Texto de referencia con informaci√≥n de hablante
3. **Metadatos**: Informaci√≥n sobre voces, configuraci√≥n, etc.

Ejemplo de uso con un sistema STT:

```python
import json
from pathlib import Path

# Cargar entrada del dataset
with open("entry_metadata.json") as f:
    entry_metadata = json.load(f)

audio_file = entry_metadata["audio_file_path"]
transcript_file = entry_metadata["transcript_file_path"]

# Cargar transcripci√≥n de referencia
with open(transcript_file) as f:
    reference = json.load(f)

# Tu sistema STT
predicted_text = your_stt_system.transcribe(audio_file)

# Comparar con referencia
reference_text = " ".join([turn["text"] for turn in reference["turns"]])
accuracy = calculate_accuracy(predicted_text, reference_text)
```

## Soluci√≥n de Problemas

### Error de Clave API
```
ValueError: OpenAI API key is required
```
‚Üí Aseg√∫rate de que el archivo `.env` est√© presente con claves API v√°lidas

### Error de Proveedor TTS
```
ValueError: Gemini TTS generator not initialized
```
‚Üí Configura `GOOGLE_API_KEY` en tu archivo `.env` para usar Gemini TTS

### Comparaci√≥n de Proveedores TTS

| Caracter√≠stica | ElevenLabs | Google Gemini |
|----------------|------------|---------------|
| **Costo** | Premium (pago) | Gratuito (con cuotas) |
| **Calidad** | Excelente | Buena |
| **Voces** | M√∫ltiples opciones | Voces est√°ndar |
| **Latencia** | Baja | Media |
| **L√≠mites** | Seg√∫n plan | Cuotas diarias |

### Recomendaciones de Uso

- **Para desarrollo/pruebas**: Usa Gemini TTS (gratuito)
- **Para producci√≥n**: Usa ElevenLabs (mejor calidad)
- **Para grandes vol√∫menes**: Combina ambos seg√∫n necesidades

### Error de Voz No Encontrada
```
Warning: No voice mapping found for speaker 'X'
```
‚Üí A√±ade mapeos de voz para todos los hablantes en tus escenarios

### Error de Memoria/Rate Limiting
‚Üí Reduce `--max-concurrent` para procesamiento por lotes

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CLI Interface ‚îÇ    ‚îÇ   Scenario   ‚îÇ    ‚îÇ   Generated     ‚îÇ
‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Definition   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Conversation   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚ñº
‚îÇ  Audio Files +  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  ElevenLabs  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Transcripts    ‚îÇ    ‚îÇ   TTS API    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   OpenAI API    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Pr√≥ximos Pasos

1. **A√±adir m√°s idiomas**: Expandir soporte multiling√ºe
2. **Ruido de fondo**: Incluir audio ambiente para mayor realismo
3. **M√©tricas autom√°ticas**: Calcular m√©tricas de calidad del dataset
4. **Integraci√≥n STT**: Conectores directos a sistemas STT populares
5. **Interfaz web**: GUI para configuraci√≥n m√°s f√°cil

## Contribuir

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature
3. A√±ade pruebas
4. Env√≠a un pull request

## Licencia

MIT License - ver archivo LICENSE para detalles.
