# STT Dataset Generator

Una herramienta para generar datasets de evaluaciÃ³n de sistemas de reconocimiento de voz (STT) usando OpenAI para generar transcripciones estructuradas y mÃºltiples proveedores TTS (ElevenLabs y Google Gemini) para crear conversaciones de audio.

## CaracterÃ­sticas

- ğŸ¤– **GeneraciÃ³n automÃ¡tica de conversaciones** usando OpenAI 
- ğŸ™ï¸ **SÃ­ntesis de voz realista** usando ElevenLabs TTS o Google Gemini TTS
- ğŸ“Š **Salida estructurada** con modelos Pydantic
- âš¡ **Procesamiento asÃ­ncrono** para generaciÃ³n eficiente en lotes
- ğŸ›ï¸ **Interfaz de lÃ­nea de comandos** fÃ¡cil de usar
- ğŸ“ **OrganizaciÃ³n automÃ¡tica** de archivos de dataset
- ğŸ”„ **MÃºltiples proveedores TTS** - ElevenLabs (premium) y Gemini (gratuito)

## InstalaciÃ³n

1. Clona el repositorio y navega al directorio:
```bash
cd Dataset_creation
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

2.b Requisito del sistema: FFmpeg (obligatorio)

FFmpeg es necesario para la manipulaciÃ³n/convertido de audio (usado por pydub y para convertir WAVâ†”MP3).

- macOS (Homebrew):
```bash
brew install ffmpeg
```

- Linux (Debian/Ubuntu):
```bash
sudo apt update && sudo apt install -y ffmpeg
```

- Linux (Fedora/RHEL):
```bash
sudo dnf install -y ffmpeg
```

- Windows (winget o Chocolatey):
```powershell
# Con Chocolatey
choco install ffmpeg
```

VerificaciÃ³n rÃ¡pida:
```bash
ffmpeg -version
```

Recuerda refrescar tu app o terminal si ffmpeg -version is not found before running the commands

3. Configura las claves API:
```bash
# Crea un archivo .env con tus claves API
echo "OPENAI_API_KEY=tu_clave_openai_aquÃ­" > .env

# Para ElevenLabs (opcional - premium)
echo "ELEVEN_API_KEY=tu_clave_elevenlabs_aquÃ­" >> .env

# Para Google Gemini TTS (opcional - gratuito)
echo "GOOGLE_API_KEY=tu_clave_google_aquÃ­" >> .env
```

## Uso RÃ¡pido

### 1. Generar una conversaciÃ³n rÃ¡pida

#### Con ElevenLabs (premium)
```bash
python cli.py quick-generate \
  --title "Consulta MÃ©dica" \
  --description "Un doctor consulta con un paciente sobre sÃ­ntomas" \
  --context "Consultorio mÃ©dico" \
  --participants "Doctor,Paciente" \
  --duration 90 \
  --difficulty medium \
  --domain medical \
  --language es \
  --tts-provider elevenlabs
```

#### Con Google Gemini TTS (gratuito)
```bash
python cli.py quick-generate \
  --title "Consulta MÃ©dica" \
  --description "Un doctor consulta con un paciente sobre sÃ­ntomas" \
  --context "Consultorio mÃ©dico" \
  --participants "Doctor,Paciente" \
  --duration 90 \
  --difficulty medium \
  --domain medical \
  --language es \
  --tts-provider gemini
```

### 2. Crear configuraciÃ³n de muestra
```bash
python cli.py create-sample-config --output scenarios.json
```

### 3. Generar dataset desde configuraciÃ³n

#### Con ElevenLabs
```bash
# Para un Ãºnico escenario (prueba)
python cli.py generate --scenarios scenarios.json --single --tts-provider elevenlabs

# Para todo el lote
python cli.py generate --scenarios scenarios.json --max-concurrent 3 --tts-provider elevenlabs
```

#### Con Google Gemini TTS
```bash
# Para un Ãºnico escenario (prueba)
python cli.py generate --scenarios scenarios.json --single --tts-provider gemini

# Para todo el lote
python cli.py generate --scenarios scenarios.json --max-concurrent 3 --tts-provider gemini
```

### 4. Generar audio desde un transcript existente

Cuando ya tienes un archivo JSON de transcripciÃ³n (estructura `GeneratedConversation`) y solo quieres sintetizar el audio:

#### ElevenLabs (premium)
```bash
python cli.py synthesize-from-transcript \
  --transcript generated_datasets/gemini_test_medication/cardiology_consultation_01_b6e406b1_transcript.json \
  --language es \
  --tts-provider elevenlabs
```

#### Google Gemini TTS (gratuito)
```bash
python cli.py synthesize-from-transcript \
  --transcript generated_datasets/gemini_test_medication/cardiology_consultation_01_b6e406b1_transcript.json \
  --language es \
  --tts-provider gemini
```

Opcional: usar tus propios mapeos de voces
```bash
python cli.py synthesize-from-transcript \
  -t path/to/transcript.json \
  -l en \
  --tts-provider gemini \
  --voice-mappings voice_mappings_gemini_en.json
```

Notas:
- Si no pasas `--output`, el archivo se crearÃ¡ junto al transcript como `<base>_conversation.mp3` (ElevenLabs) o `<base>_conversation.wav` (Gemini).
- Si no pasas `--voice-mappings`, se cargarÃ¡n automÃ¡ticamente los mapeos por idioma y proveedor.

## GuÃ­a Paso a Paso Completa

Esta guÃ­a te lleva desde la configuraciÃ³n inicial hasta la generaciÃ³n de datasets listos para evaluaciÃ³n STT.

### Paso 1: ConfiguraciÃ³n Inicial

#### 1.1 Instalar Dependencias
```bash
# Instalar todas las dependencias requeridas
pip install -r requirements.txt
```

#### 1.2 Configurar Variables de Entorno
Crea un archivo `.env` en el directorio raÃ­z:
```bash
# API Keys requeridas
OPENAI_API_KEY=your_openai_api_key_here

# TTS Provider Keys (al menos una requerida)
ELEVEN_API_KEY=your_elevenlabs_api_key_here      # Para ElevenLabs (premium)
GOOGLE_API_KEY=your_google_api_key_here          # Para Google Gemini TTS (gratuito)
```

**Nota**: AsegÃºrate de que las claves API tengan permisos adecuados:
- **OpenAI**: Para usar GPT-4 en generaciÃ³n de conversaciones
- **ElevenLabs**: Para sÃ­ntesis de voz premium (requiere suscripciÃ³n)
- **Google**: Para Gemini TTS (gratuito con cuotas)

### Paso 2: Preparar Archivos de ConfiguraciÃ³n

#### 2.1 Crear Archivo de Escenarios
Los escenarios definen las conversaciones que se generarÃ¡n:

```bash
# Crear archivo de escenarios bÃ¡sico con ejemplos mÃ©dicos
python cli.py create-sample-config
```

Esto crea `scenarios.json` con ejemplos de conversaciones mÃ©dicas especializadas.

#### 2.2 Editar Escenarios Personalizados
Edita `scenarios.json` para definir tus propios escenarios:

```json
{
  "scenario_id": "consulta_cardiologia_01",
  "title": "Consulta CardiologÃ­a - Arritmias",
  "description": "CardiÃ³logo explica arritmias complejas al paciente",
  "context": "Consulta especializada donde el cardiÃ³logo explica arritmias ventriculares y discute anticoagulantes",
  "participants": ["CardiÃ³logo", "Paciente"],
  "target_duration": 180,
  "difficulty_level": "hard",
  "language": "es",
  "domain": "cardiology"
}
```

**Consejos para editar escenarios:**
- **scenario_id**: Identificador Ãºnico, usa formato `tipo_numero`
- **participants**: Roles que participarÃ¡n (deben existir en `voice_mappings_*.json`)
- **difficulty_level**: "easy", "medium", "hard" (afecta complejidad tÃ©cnica)
- **language**: "es" para espaÃ±ol, "en" para inglÃ©s
- **target_duration**: DuraciÃ³n objetivo en segundos (180-300 recomendado)

#### 2.3 Configurar Mapeos de Voces
Los archivos `voice_mappings_es.json` y `voice_mappings_en.json` mapean roles a voces de ElevenLabs:

```json
{
  "speaker_name": "CardiÃ³logo",
  "voice_id": "ID_DE_VOICE_ELEVENLABS",
  "voice_name": "Nombre de la Voz",
  "voice_description": "Voz masculina profesional para cardiÃ³logos"
}
```

**Para obtener voice_id de ElevenLabs:**
Visitar
https://elevenlabs.io/app/voice-library
Hacer click en los 3 puntos de la derecha de la voz deseada
Click en "Copy Voice ID"

O desde la terminal:
```bash
# Listar voces disponibles (requiere API key configurada)
curl -X GET "https://api.elevenlabs.io/v1/voices" \
  -H "xi-api-key: $ELEVEN_API_KEY"
```

### Paso 3: Generar Dataset BÃ¡sico

#### 3.1 GeneraciÃ³n RÃ¡pida (Prueba)
```bash
# Generar una conversaciÃ³n simple para probar el sistema
python cli.py quick-generate \
  --context "Consulta mÃ©dica bÃ¡sica sobre sÃ­ntomas de gripe" \
  --participants "Doctor,Paciente" \
  --language es
```

**Resultado:** Un archivo MP3 y JSON en `generated_datasets/quick_*`
- `conversation.mp3`: Audio de la conversaciÃ³n generada
- `conversation.json`: TranscripciÃ³n estructurada con metadatos

#### 3.2 GeneraciÃ³n por Lotes
```bash
# Generar mÃºltiples conversaciones desde archivo de escenarios
python cli.py generate \
  --scenarios scenarios.json \
  --max-concurrent 2
```

**Opciones importantes:**
- `--max-concurrent`: NÃºmero de conversaciones a generar en paralelo (2-5 recomendado)
- `--output-dir`: Directorio personalizado para salida
- `--language`: Idioma especÃ­fico ("es", "en", "auto")

**Resultado esperado:**
```
generated_datasets/
â””â”€â”€ batch_20240101_120000/
    â”œâ”€â”€ conversation_01.json          # TranscripciÃ³n estructurada
    â”œâ”€â”€ conversation_01.mp3           # Audio generado
    â”œâ”€â”€ conversation_02.json
    â”œâ”€â”€ conversation_02.mp3
    â””â”€â”€ metadata.json                 # InformaciÃ³n del lote
```

### Paso 4: Post-Procesamiento de Audio (Opcional pero Recomendado)

#### 4.1 AÃ±adir Variabilidad Realista
```bash
# Procesar un archivo individual con efectos aleatorios
python cli.py process-audio \
  -i generated_datasets/batch_xxx/conversation_01.mp3 \
  --noise-level 0.05 \
  --speed-variation 0.1 \
  --volume-variation 0.2 \
  --seed 42
```

#### 4.2 Procesar Directorio Completo
```bash
# Procesar todo un lote con efectos aleatorios
python cli.py process-audio \
  -i generated_datasets/batch_xxx \
  --noise-level 0.03 \
  --speed-variation 0.15 \
  --volume-variation 0.3
```

**Efectos aplicados aleatoriamente:**
- **Ruido de fondo**: Simula ambientes ruidosos (oficinas, hospitales)
- **VariaciÃ³n de velocidad**: Diferentes ritmos de habla (Â±10-15%) (WIP)
- **VariaciÃ³n de volumen**: Diferentes distancias de grabaciÃ³n (Â±0.2-0.3dB) (WIP)

**Resultado:**
```
conversation_01.mp3
â”œâ”€â”€ conversation_01_processed_a1b2c3.mp3    # Con ruido de fondo
â”œâ”€â”€ conversation_01_processed_d4e5f6.mp3    # Velocidad modificada
â””â”€â”€ conversation_01_processed_g7h8i9.mp3    # Volumen ajustado
```

### Paso 5: ValidaciÃ³n y VerificaciÃ³n

#### 5.1 Validar Dataset
```bash
# Verificar integridad del dataset generado
python cli.py validate \
  --directory generated_datasets/batch_xxx
```

**Verificaciones realizadas:**
- âœ… Archivos de audio existen y son vÃ¡lidos
- âœ… Transcripciones JSON tienen estructura correcta
- âœ… Metadatos incluyen informaciÃ³n requerida
- âœ… Duraciones de audio coinciden con expectativas

#### 5.2 Obtener InformaciÃ³n del Dataset
```bash
# Mostrar estadÃ­sticas del lote generado
python cli.py info \
  --directory generated_datasets/batch_xxx
```

### Paso 6: Flujo de Trabajo Completo

#### Ejemplo: Dataset MÃ©dico en EspaÃ±ol Completo
```bash
# 1. Configurar API keys
echo "OPENAI_API_KEY=sk-..." > .env
echo "ELEVEN_API_KEY=..." >> .env
echo "GOOGLE_API_KEY=..." >> .env

# 2. Crear escenarios mÃ©dicos de ejemplo
python cli.py create-sample-config

# 3. Editar escenarios para especialidades especÃ­ficas
# (editar scenarios.json manualmente)

# 4. Generar dataset bÃ¡sico con ElevenLabs (premium)
python cli.py generate \
  --scenarios scenarios.json \
  --max-concurrent 3 \
  --language es \
  --tts-provider elevenlabs

# O con Google Gemini TTS (gratuito)
python cli.py generate \
  --scenarios scenarios.json \
  --max-concurrent 3 \
  --language es \
  --tts-provider gemini

# 5. AÃ±adir variabilidad para evaluaciÃ³n robusta
python cli.py process-audio \
  -i generated_datasets/batch_latest \
  --noise-level 0.05 \
  --speed-variation 0.1

# 6. Validar resultado final
python cli.py validate \
  --directory generated_datasets/batch_latest
```

### Paso 7: Estructura Final del Dataset

DespuÃ©s de completar todos los pasos, tendrÃ¡s:

```
generated_datasets/
â””â”€â”€ batch_20240101_120000/
    â”œâ”€â”€ metadata.json                    # InformaciÃ³n del lote
    â”œâ”€â”€ conversation_01.json            # TranscripciÃ³n original
    â”œâ”€â”€ conversation_01.mp3             # Audio original
    â”œâ”€â”€ conversation_01_processed_abc123.mp3  # Audio procesado 1
    â”œâ”€â”€ conversation_01_processed_def456.mp3  # Audio procesado 2
    â”œâ”€â”€ conversation_02.json
    â”œâ”€â”€ conversation_02.mp3
    â””â”€â”€ batch_cardiology_consultation_01_processed/
        â””â”€â”€ [archivos procesados adicionales]
```

### Consejos y Mejores PrÃ¡cticas

#### ConfiguraciÃ³n de Escenarios
- **DifÃ­cil**: Incluye terminologÃ­a mÃ©dica especÃ­fica, nombres de drogas, sÃ­ntomas complejos
- **Participantes**: Usa roles especÃ­ficos (CardiÃ³logo, Enfermera, Familiar del Paciente)
- **DuraciÃ³n**: 180-300 segundos para conversaciones realistas
- **Dominio**: Especifica el campo mÃ©dico para terminologÃ­a apropiada

#### OptimizaciÃ³n de Audio
- **Post-procesamiento**: Mejora drÃ¡sticamente la evaluaciÃ³n STT en condiciones reales
- **Seeds**: Usa `--seed` para resultados reproducibles en tests
- **Variabilidad**: Combina diferentes niveles de ruido y velocidad

#### GestiÃ³n de Recursos
- **Concurrente**: Ajusta `--max-concurrent` segÃºn lÃ­mites de tu plan de API
- **Lotes**: Divide escenarios grandes en archivos separados
- **Monitoreo**: Revisa logs para identificar problemas de API temprano

### 4. Procesar audio (opcional)
```bash
# Procesar archivo individual con efectos aleatorios
python cli.py process-audio -i archivo.mp3 --seed 42

# Procesar directorio completo
python cli.py process-audio -i ./generated_datasets/batch_xxx

# Procesar con parÃ¡metros personalizados
python cli.py process-audio \
  -i ./generated_datasets/batch_xxx \
  --noise-level 0.08 \
  --speed-variation 0.15 \
  --volume-variation 0.3 \
  --noise-types "white" \
  --seed 123
```

### 5. Validar dataset generado
```bash
python cli.py validate --directory ./generated_datasets/batch_20231201_143022
```

## Estructura de Archivos de Salida

```
generated_datasets/
â””â”€â”€ batch_20231201_143022/
    â”œâ”€â”€ batch_20231201_143022_metadata.json    # Metadatos del lote
    â”œâ”€â”€ medical_consultation_01_a1b2c3d4_conversation.mp3      # Audio
    â”œâ”€â”€ medical_consultation_01_a1b2c3d4_transcript.json       # TranscripciÃ³n
    â”œâ”€â”€ medical_consultation_01_a1b2c3d4_metadata.json         # Metadatos entrada
    â””â”€â”€ ... (mÃ¡s entradas)
```

## ConfiguraciÃ³n de Escenarios

Los escenarios se definen en formato JSON. Ejemplo:

```json
[
  {
    "scenario_id": "medical_consultation_01",
    "title": "Consulta MÃ©dica",
    "description": "Un doctor consulta con un paciente sobre sÃ­ntomas",
    "context": "Consultorio mÃ©dico donde un doctor examina a un paciente con sÃ­ntomas de gripe",
    "participants": ["Doctor", "Paciente"],
    "target_duration": 90,
    "difficulty_level": "medium",
    "language": "en",
    "domain": "medical"
  }
]
```

### Campos de Escenario

- **scenario_id**: Identificador Ãºnico
- **title**: TÃ­tulo de la conversaciÃ³n
- **description**: DescripciÃ³n breve
- **context**: Contexto o setting para la conversaciÃ³n
- **participants**: Lista de nombres/roles de participantes
- **target_duration**: DuraciÃ³n objetivo en segundos
- **difficulty_level**: "easy", "medium", "hard"
- **language**: CÃ³digo de idioma (ej: "en", "es")
- **domain**: Dominio especÃ­fico (medical, business, casual, etc.)

### Niveles de Dificultad

- **Easy**: Frases claras y simples, superposiciones mÃ­nimas, habla formal
- **Medium**: Habla natural con algunos elementos informales, superposiciones ocasionales  
- **Hard**: Frases complejas, habla informal, interrupciones, referencias a ruido de fondo

## ConfiguraciÃ³n de Voces

El sistema carga automÃ¡ticamente los mapeos de voz desde archivos JSON segÃºn el idioma especificado. Puedes personalizar las voces editando los archivos `voice_mappings_en.json` (inglÃ©s) y `voice_mappings_es.json` (espaÃ±ol)

### Mapeos por Idioma
- **EspaÃ±ol**: `voice_mappings_es.json` (25 voces optimizadas para espaÃ±ol)
- **InglÃ©s**: `voice_mappings_en.json` (25 voces optimizadas para inglÃ©s)
- **SelecciÃ³n automÃ¡tica**: Basada en el campo `language` del escenario

### Voces Recomendadas por Especialidad MÃ©dica
**Profesionales MÃ©dicos:**
- **CardiÃ³logo**: Rachel (voz profesional y precisa)
- **OncÃ³logo/Radio-oncÃ³logo**: Sarah (voz autoritaria y empÃ¡tica)
- **Neurocirujano/NeurÃ³logo**: Adam (voz calmada y tÃ©cnica)
- **Psiquiatra**: Sarah (voz empÃ¡tica y profesional)
- **Cirujano/AnestesiÃ³logo**: Rachel (voz autoritaria y calmada)

**Pacientes y Familiares:**
- **Paciente**: Domi (voz conversacional y natural)
- **Padre**: Domi (voz preocupada masculina)
- **Madre**: Rachel (voz angustiada femenina)
- **Familiar**: Domi (voz familiar preocupada)

**Personal MÃ©dico Auxiliar:**
- **Enfermera**: Sarah (voz clara y profesional)
- **Residente**: Josh (voz joven y tÃ©cnica)
- **Perfusionista**: Josh (voz tÃ©cnica especializada)
- **Endoscopista**: Adam (voz tÃ©cnica especializada)

## ConfiguraciÃ³n de Audio

La herramienta utiliza **ElevenLabs v3** con configuraciÃ³n optimizada para STT:

### ConfiguraciÃ³n Predeterminada
- **Modelo**: `eleven_v3` (modelo mÃ¡s avanzado con audio tags)
- **Formato**: `mp3_44100_128` (alta calidad, tamaÃ±o optimizado)
- **Estabilidad**: `0.5` (equilibrio entre expresividad y consistencia)
  - `0.3`: Creativa (mÃ¡s emocional, mejor para tags)
  - `0.5`: Natural (equilibrio recomendado)
  - `0.8`: Robusta (muy estable, menos expresiva)
- **Speaker Boost**: `True` (mejora similitud con voz original)
- **Text Normalization**: `auto` (manejo automÃ¡tico de nÃºmeros y sÃ­mbolos)
- **Audio Tags**: `True` (habilitado para expresividad emocional)

### Audio Tags AutomÃ¡ticos (v3)
La herramienta aplica automÃ¡ticamente audio tags basados en caracterÃ­sticas de voz generadas por OpenAI:

**Mapeo AutomÃ¡tico de CaracterÃ­sticas a Tags:**
- `"anxious"` â†’ `[nervous]`
- `"whispering"` â†’ `[whispers]`
- `"excited"` â†’ `[excited]`
- `"questioning"` â†’ `[questioning]`
- `"professional"` â†’ `[professional]`
- `"warm"` â†’ `[warm]`
- `"curious"` â†’ `[curious]`
- `"frustrated"` â†’ `[frustrated]`
- `"reassuring"` â†’ `[reassuring]`

**Tags Contextuales Adicionales:**
- `[pause]` - Pausas naturales entre turnos
- `[emphasis]` - Ã‰nfasis en tÃ©rminos tÃ©cnicos, nombres de medicamentos, siglas mÃ©dicas
- `[sighs]` - Suspiros para marcadores de duda ("um", "well", "uh")

### ConfiguraciÃ³n por Idioma
- **EspaÃ±ol (`--language es`)**: Usa mapeos optimizados para espaÃ±ol
- **InglÃ©s (`--language en`)**: Usa mapeos optimizados para inglÃ©s
- **Otros idiomas**: Compatibilidad automÃ¡tica con voces multilingÃ¼es

### Calidad de Audio
- **Archivo de salida**: MP3 de alta calidad (~1.2-1.5MB por conversaciÃ³n)
- **Tasa de muestreo**: 44.1kHz (calidad CD)
- **Bitrate**: 128kbps (equilibrio calidad/tamaÃ±o)
- **ConversiÃ³n**: Una sola llamada API usando Text to Dialogue

## Procesamiento de Audio Post-GeneraciÃ³n

El sistema incluye herramientas avanzadas para **post-procesamiento de audio** que aÃ±aden variabilidad realista a los datasets, mejorando la evaluaciÃ³n de sistemas STT en condiciones del mundo real.

### Efectos Disponibles

#### **Ruido de Fondo**
- **Tipos**: Blanco, rosa, marrÃ³n (dependiendo de la versiÃ³n de pydub)
- **Nivel**: Configurable de 0.0 a 0.2
- **PropÃ³sito**: Simular ambientes ruidosos (oficinas, hospitales, transporte)

#### **VariaciÃ³n de Velocidad**
- **Rango**: Â± porcentaje configurable (default: Â±10%)
- **AplicaciÃ³n**: 70% de probabilidad de modificaciÃ³n
- **PropÃ³sito**: Simular diferentes ritmos de habla

#### **VariaciÃ³n de Volumen**
- **Rango**: Â±dB configurable (default: Â±0.2dB)
- **AplicaciÃ³n**: 80% de probabilidad de modificaciÃ³n
- **PropÃ³sito**: Simular diferentes distancias y condiciones de grabaciÃ³n

### Beneficios para EvaluaciÃ³n STT

âœ… **Mayor Robustez**: Entrenar modelos con audio variable
âœ… **Realismo**: Simular condiciones del mundo real
âœ… **Diversidad**: Crear mÃºltiples variantes del mismo contenido
âœ… **EvaluaciÃ³n**: Medir rendimiento en condiciones adversas
âœ… **Reproducibilidad**: Usar `--seed` para resultados consistentes

### Archivos Generados

```
original_audio.mp3
â”œâ”€â”€ original_audio_processed_a1b2c3.mp3  # Con ruido + velocidad
â”œâ”€â”€ original_audio_processed_d4e5f6.mp3  # Solo volumen modificado
â””â”€â”€ original_audio_processed_g7h8i9.mp3  # Sin modificaciones
```

### Ejemplos de Uso

```bash
# Dataset bÃ¡sico para evaluaciÃ³n estÃ¡ndar
python cli.py generate --scenarios scenarios.json

# Dataset con variabilidad para evaluaciÃ³n robusta
python cli.py generate --scenarios scenarios.json
python cli.py process-audio -i ./generated_datasets/batch_xxx \
  --noise-level 0.05 --speed-variation 0.1 --volume-variation 0.2

# Crear mÃºltiples variantes de un archivo especÃ­fico
python cli.py process-audio -i archivo.mp3 --seed 42
python cli.py process-audio -i archivo.mp3 --seed 43
python cli.py process-audio -i archivo.mp3 --seed 44
```

## API ProgramÃ¡tica

TambiÃ©n puedes usar la herramienta programÃ¡ticamente:

```python
from dotenv import load_dotenv
from dataset_generator import STTDatasetGenerator
from models import ConversationScenario

load_dotenv()

# Inicializar generador
generator = STTDatasetGenerator()

# Crear escenario
scenario = ConversationScenario(
    scenario_id="test_01",
    title="ConversaciÃ³n de Prueba",
    description="Una conversaciÃ³n simple para probar",
    context="Llamada telefÃ³nica casual",
    participants=["Alice", "Bob"],
    target_duration=60,
    difficulty_level="easy"
)

# Generar entrada de dataset
entry = generator.generate_single_dataset_entry(scenario)
print(f"Generado: {entry.entry_id}")
```

## Uso para EvaluaciÃ³n STT

Los datasets generados estÃ¡n listos para evaluaciÃ³n STT:

1. **Archivo de Audio**: ConversaciÃ³n multiparlante en MP3
2. **TranscripciÃ³n**: Texto de referencia con informaciÃ³n de hablante
3. **Metadatos**: InformaciÃ³n sobre voces, configuraciÃ³n, etc.

Ejemplo de uso con un sistema STT:

```python
import json
from pathlib import Path

# Cargar entrada del dataset
with open("entry_metadata.json") as f:
    entry_metadata = json.load(f)

audio_file = entry_metadata["audio_file_path"]
transcript_file = entry_metadata["transcript_file_path"]

# Cargar transcripciÃ³n de referencia
with open(transcript_file) as f:
    reference = json.load(f)

# Tu sistema STT
predicted_text = your_stt_system.transcribe(audio_file)

# Comparar con referencia
reference_text = " ".join([turn["text"] for turn in reference["turns"]])
accuracy = calculate_accuracy(predicted_text, reference_text)
```

## SoluciÃ³n de Problemas

### Error de Clave API
```
ValueError: OpenAI API key is required
```
â†’ AsegÃºrate de que el archivo `.env` estÃ© presente con claves API vÃ¡lidas

### Error de Proveedor TTS
```
ValueError: Gemini TTS generator not initialized
```
â†’ Configura `GOOGLE_API_KEY` en tu archivo `.env` para usar Gemini TTS

### ComparaciÃ³n de Proveedores TTS

| CaracterÃ­stica | ElevenLabs | Google Gemini |
|----------------|------------|---------------|
| **Costo** | Premium (pago) | Gratuito (con cuotas) |
| **Calidad** | Excelente | Buena |
| **Voces** | MÃºltiples opciones | Voces estÃ¡ndar |
| **Latencia** | Baja | Media |
| **LÃ­mites** | SegÃºn plan | Cuotas diarias |

### Recomendaciones de Uso

- **Para desarrollo/pruebas**: Usa Gemini TTS (gratuito)
- **Para producciÃ³n**: Usa ElevenLabs (mejor calidad)
- **Para grandes volÃºmenes**: Combina ambos segÃºn necesidades

### Error de Voz No Encontrada
```
Warning: No voice mapping found for speaker 'X'
```
â†’ AÃ±ade mapeos de voz para todos los hablantes en tus escenarios

### Error de Memoria/Rate Limiting
â†’ Reduce `--max-concurrent` para procesamiento por lotes

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Interface â”‚    â”‚   Scenario   â”‚    â”‚   Generated     â”‚
â”‚                 â”‚â”€â”€â”€â–¶â”‚ Definition   â”‚â”€â”€â”€â–¶â”‚  Conversation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â–¼
â”‚  Audio Files +  â”‚â—€â”€â”€â”€â”‚  ElevenLabs  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transcripts    â”‚    â”‚   TTS API    â”‚â—€â”€â”€â”€â”‚   OpenAI API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrÃ³ximos Pasos

1. **AÃ±adir mÃ¡s idiomas**: Expandir soporte multilingÃ¼e
2. **Ruido de fondo**: Incluir audio ambiente para mayor realismo
3. **MÃ©tricas automÃ¡ticas**: Calcular mÃ©tricas de calidad del dataset
4. **IntegraciÃ³n STT**: Conectores directos a sistemas STT populares
5. **Interfaz web**: GUI para configuraciÃ³n mÃ¡s fÃ¡cil

## Contribuir

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature
3. AÃ±ade pruebas
4. EnvÃ­a un pull request

## Licencia

MIT License - ver archivo LICENSE para detalles.
